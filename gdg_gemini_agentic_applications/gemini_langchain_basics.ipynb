{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GDG Ahlen / Incremental design of LLM-powered agentic applications](https://www.youtube.com/watch?v=uIQlMSX5gx4)\n",
    "\n",
    "Resources:\n",
    "- [Google AI Studio](https://python.langchain.com/docs/integrations/chat/google_generative_ai/)\n",
    "     - need to get `GOOGLE_API_KEY`\n",
    "- [LangChain: GoogleGenerativeAI](https://python.langchain.com/docs/integrations/chat/google_generative_ai/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Basics of instrumenting LLM with Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Gemini in LangChain\n",
    "\n",
    "Important to set Experimental model of Gemini in `ChatGoogleGenerativeAI.model` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import env variables from `.env` file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Check for Google GEMINI API KEY\n",
    "import os\n",
    "assert \"GOOGLE_API_KEY\" in os.environ\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    max_tokens=None,\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    temperature=1,\n",
    "    top_k=1,\n",
    "    top_p=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is a question: \"Tell me who are you, dear?\"\n",
      "\n",
      "It indicates:\n",
      "\n",
      "*   **A request for identification:** Someone is asking another to identify themselves.\n",
      "*   **Informality:** The use of \"dear\" suggests a familiar or affectionate tone.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Process this text: {input}\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"input\": \"Tell me who are you, dear?\"\n",
    "})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's great! Programming is a valuable and versatile skill. Do you have any specific areas of programming you're interested in exploring, like web development, data science, or game development?  I can help you find resources or understand different paths.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are export in {topic} and should answering to user inputs, provide concise and simple answer, also suggest tradeoffs\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\", \n",
    "            \"{input}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"topic\": \"Maching Learning\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-modal prompt with structured response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![llm_in_production.png](images/llm_in_production.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal prompt without structured response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The image is a diagram illustrating an LLM (Large Language Model) pipeline and its applications.\\n\\nHere\\'s a breakdown:\\n\\n**Top Level: AI Application + Data Products**\\n\\n*   **Q&A Webapp:** A web application that allows users to ask questions and receive answers generated by an LLM.\\n*   **Chatbot:** A conversational AI system that interacts with users through text or voice.\\n*   **Model as an API:** The LLM is exposed as an API (Application Programming Interface), allowing other applications to access and use its capabilities.\\n\\n**Middle Level: LLM Pipeline**\\n\\nThis section describes the steps involved in processing text using an LLM.\\n\\n*   **Corpus Creation:** Gathering and preparing a large dataset of text for training the LLM.\\n*   **Text Pre-processing:** Cleaning and formatting the text data to make it suitable for the LLM.\\n*   **Prompt Engineering:** Crafting specific prompts or instructions to guide the LLM\\'s responses.\\n*   **LLM Inference:** Using the LLM to generate output based on the input prompt.\\n*   **Generated Text:** The final output produced by the LLM.\\n\\n**Bottom Level: LLM Model(s)**\\n\\nThis section lists specific LLM models.\\n\\n*   **GPT-3.5 and GPT-4.0:** Models developed by OpenAI.\\n*   **LLaMA:** An LLM developed by Meta (Facebook).\\n*   **Hugging Face:** A platform that hosts and provides access to various LLMs.\\n*   **MPT:** Another LLM, with the implication that there are \"and more...\" other models.\\n\\nThe arrows indicate the flow of information: LLM models feed into the LLM pipeline, which in turn powers the AI applications and data products.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-c81256e8-88c3-4a00-95b2-dbfe5f6a240e-0' usage_metadata={'input_tokens': 1813, 'output_tokens': 377, 'total_tokens': 2190, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "with open(\"images/llm_in_production.png\", \"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "response = llm.invoke([\n",
    "    HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": \"What's on this image?\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{encoded_image}\"}\n",
    "    ])\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal prompt with structured response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseSchema</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">models</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLModel</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'GPT 3.5'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">company</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'OpenAI'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">parameters</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'175 billion'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Versatile'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Costly'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLModel</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'GPT 4.0'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">company</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'OpenAI'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">parameters</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1.76 trillion'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Cutting edge'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Very costly'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLModel</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLaMA'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">company</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Meta'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">parameters</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'7B to 65B'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Open source'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Not as versatile as others'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLModel</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hugging Face Models'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">company</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hugging Face'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">parameters</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Varies'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Open source and community support'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Can be difficult to implement'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLModel</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'MPT'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">company</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'MPT'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">parameters</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'7B to 30B'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Open source'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Not as versatile as others'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mResponseSchema\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmodels\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mLLModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmodel\u001b[0m=\u001b[32m'GPT 3.5'\u001b[0m, \u001b[33mcompany\u001b[0m=\u001b[32m'OpenAI'\u001b[0m, \u001b[33mparameters\u001b[0m=\u001b[32m'175 billion'\u001b[0m, \u001b[33mpros\u001b[0m=\u001b[32m'Versatile'\u001b[0m, \u001b[33mcons\u001b[0m=\u001b[32m'Costly'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mLLModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'GPT 4.0'\u001b[0m,\n",
       "            \u001b[33mcompany\u001b[0m=\u001b[32m'OpenAI'\u001b[0m,\n",
       "            \u001b[33mparameters\u001b[0m=\u001b[32m'1.76 trillion'\u001b[0m,\n",
       "            \u001b[33mpros\u001b[0m=\u001b[32m'Cutting edge'\u001b[0m,\n",
       "            \u001b[33mcons\u001b[0m=\u001b[32m'Very costly'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mLLModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'LLaMA'\u001b[0m,\n",
       "            \u001b[33mcompany\u001b[0m=\u001b[32m'Meta'\u001b[0m,\n",
       "            \u001b[33mparameters\u001b[0m=\u001b[32m'7B to 65B'\u001b[0m,\n",
       "            \u001b[33mpros\u001b[0m=\u001b[32m'Open source'\u001b[0m,\n",
       "            \u001b[33mcons\u001b[0m=\u001b[32m'Not as versatile as others'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mLLModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'Hugging Face Models'\u001b[0m,\n",
       "            \u001b[33mcompany\u001b[0m=\u001b[32m'Hugging Face'\u001b[0m,\n",
       "            \u001b[33mparameters\u001b[0m=\u001b[32m'Varies'\u001b[0m,\n",
       "            \u001b[33mpros\u001b[0m=\u001b[32m'Open source and community support'\u001b[0m,\n",
       "            \u001b[33mcons\u001b[0m=\u001b[32m'Can be difficult to implement'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mLLModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'MPT'\u001b[0m,\n",
       "            \u001b[33mcompany\u001b[0m=\u001b[32m'MPT'\u001b[0m,\n",
       "            \u001b[33mparameters\u001b[0m=\u001b[32m'7B to 30B'\u001b[0m,\n",
       "            \u001b[33mpros\u001b[0m=\u001b[32m'Open source'\u001b[0m,\n",
       "            \u001b[33mcons\u001b[0m=\u001b[32m'Not as versatile as others'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from rich import print\n",
    "\n",
    "class LLModel(BaseModel):\n",
    "    model: str = Field(description=\"Model name\")\n",
    "    company: str = Field(description=\"The company name created model\")\n",
    "    parameters: str = Field(description=\"Rough estimation of number of model parameters\")\n",
    "    pros: str = Field(description=\"Pros of the model\")\n",
    "    cons: str = Field(description=\"Cons of the model\")\n",
    "\n",
    "class ResponseSchema(BaseModel):\n",
    "    models: List[LLModel]\n",
    "\n",
    "\n",
    "llm_structured = llm.with_structured_output(ResponseSchema)\n",
    "\n",
    "\n",
    "with open(\"images/llm_in_production.png\", \"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "response = llm_structured.invoke([\n",
    "    HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": \"Provide information about LLM models on the image\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{encoded_image}\"}\n",
    "    ])\n",
    "])\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch prompts without structrued response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Feedforward neural networks are the simplest type of artificial neural network. Information flows in one </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">direction: from input to output. They consist of layers of interconnected nodes, where each connection has a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">weight. These weights are adjusted during training to minimize the difference between the network's output and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">desired output.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Convolutional Neural Networks (CNNs) are a type of deep learning architecture primarily used for image and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">video processing. They use convolutional layers to automatically and adaptively learn spatial hierarchies of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">features from input data. Pooling layers reduce dimensionality, and fully connected layers perform </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">classification.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Recurrent Neural Networks (RNNs) are designed for sequential data. They have a \"memory\" of past inputs, using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">feedback loops to process information over time. This makes them suitable for tasks like language modeling and time</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">series analysis.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Generative Adversarial Networks (GANs) use two neural networks: a generator that creates fake data and a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discriminator that tries to distinguish between real and fake data. Through adversarial training, the generator </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learns to produce increasingly realistic data, fooling the discriminator.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A Transformer is a neural network architecture that uses self-attention mechanisms to weigh the importance of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different parts of the input sequence. This allows it to handle long-range dependencies and is commonly used in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural language processing for tasks like translation and text generation.'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"Feedforward neural networks are the simplest type of artificial neural network. Information flows in one \u001b[0m\n",
       "\u001b[32mdirection: from input to output. They consist of layers of interconnected nodes, where each connection has a \u001b[0m\n",
       "\u001b[32mweight. These weights are adjusted during training to minimize the difference between the network's output and the \u001b[0m\n",
       "\u001b[32mdesired output.\"\u001b[0m,\n",
       "    \u001b[32m'Convolutional Neural Networks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are a type of deep learning architecture primarily used for image and \u001b[0m\n",
       "\u001b[32mvideo processing. They use convolutional layers to automatically and adaptively learn spatial hierarchies of \u001b[0m\n",
       "\u001b[32mfeatures from input data. Pooling layers reduce dimensionality, and fully connected layers perform \u001b[0m\n",
       "\u001b[32mclassification.'\u001b[0m,\n",
       "    \u001b[32m'Recurrent Neural Networks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are designed for sequential data. They have a \"memory\" of past inputs, using \u001b[0m\n",
       "\u001b[32mfeedback loops to process information over time. This makes them suitable for tasks like language modeling and time\u001b[0m\n",
       "\u001b[32mseries analysis.'\u001b[0m,\n",
       "    \u001b[32m'Generative Adversarial Networks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGANs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m use two neural networks: a generator that creates fake data and a \u001b[0m\n",
       "\u001b[32mdiscriminator that tries to distinguish between real and fake data. Through adversarial training, the generator \u001b[0m\n",
       "\u001b[32mlearns to produce increasingly realistic data, fooling the discriminator.'\u001b[0m,\n",
       "    \u001b[32m'A Transformer is a neural network architecture that uses self-attention mechanisms to weigh the importance of \u001b[0m\n",
       "\u001b[32mdifferent parts of the input sequence. This allows it to handle long-range dependencies and is commonly used in \u001b[0m\n",
       "\u001b[32mnatural language processing for tasks like translation and text generation.'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"Concise explanating using less 50 words of following thing: {input}\")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "prompt_values = [\n",
    "    {\"input\": \"Feedforward Neural Networks\"},\n",
    "    {\"input\": \"Convolutional Neural Networks\"},\n",
    "    {\"input\": \"Recurrent Neural Networks\"},\n",
    "    {\"input\": \"Generative Adversarial Networks\"},\n",
    "]\n",
    "\n",
    "result = chain.batch(prompt_values)\n",
    "\n",
    "# we will get a list with the two plain text outputs\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch prompts with structrued response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseSchema</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">neural_networks</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NeuralNetworkModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Feedforward Neural Networks'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1958'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">common_usage</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Image recognition, natural language processing'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Simple to implement, well-suited for many tasks'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Can be computationally expensive, prone to overfitting'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseSchema</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">neural_networks</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NeuralNetworkModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Convolutional Neural Networks'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1989'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">common_usage</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'image recognition, object detection'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Excellent feature extraction, translation invariance'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'computationally expensive, requires large datasets'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseSchema</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">neural_networks</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NeuralNetworkModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Recurrent Neural Networks'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1980'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">common_usage</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Good for processing sequential data'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Can handle variable length inputs'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Vanishing gradients problem'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseSchema</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">neural_networks</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NeuralNetworkModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Generative Adversarial Networks'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2014'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">common_usage</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'image generation, data augmentation, and anomaly detection'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">pros</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'capable of generating high-quality and realistic samples, and can learn complex data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">distributions'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">cons</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'training instability, mode collapse, and difficulty in evaluating the quality of generated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">samples'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mResponseSchema\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mneural_networks\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mNeuralNetworkModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mname\u001b[0m=\u001b[32m'Feedforward Neural Networks'\u001b[0m,\n",
       "                \u001b[33myear\u001b[0m=\u001b[32m'1958'\u001b[0m,\n",
       "                \u001b[33mcommon_usage\u001b[0m=\u001b[32m'Image recognition, natural language processing'\u001b[0m,\n",
       "                \u001b[33mpros\u001b[0m=\u001b[32m'Simple to implement, well-suited for many tasks'\u001b[0m,\n",
       "                \u001b[33mcons\u001b[0m=\u001b[32m'Can be computationally expensive, prone to overfitting'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mResponseSchema\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mneural_networks\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mNeuralNetworkModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mname\u001b[0m=\u001b[32m'Convolutional Neural Networks'\u001b[0m,\n",
       "                \u001b[33myear\u001b[0m=\u001b[32m'1989'\u001b[0m,\n",
       "                \u001b[33mcommon_usage\u001b[0m=\u001b[32m'image recognition, object detection'\u001b[0m,\n",
       "                \u001b[33mpros\u001b[0m=\u001b[32m'Excellent feature extraction, translation invariance'\u001b[0m,\n",
       "                \u001b[33mcons\u001b[0m=\u001b[32m'computationally expensive, requires large datasets'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mResponseSchema\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mneural_networks\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mNeuralNetworkModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mname\u001b[0m=\u001b[32m'Recurrent Neural Networks'\u001b[0m,\n",
       "                \u001b[33myear\u001b[0m=\u001b[32m'1980'\u001b[0m,\n",
       "                \u001b[33mcommon_usage\u001b[0m=\u001b[32m'Good for processing sequential data'\u001b[0m,\n",
       "                \u001b[33mpros\u001b[0m=\u001b[32m'Can handle variable length inputs'\u001b[0m,\n",
       "                \u001b[33mcons\u001b[0m=\u001b[32m'Vanishing gradients problem'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mResponseSchema\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mneural_networks\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mNeuralNetworkModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mname\u001b[0m=\u001b[32m'Generative Adversarial Networks'\u001b[0m,\n",
       "                \u001b[33myear\u001b[0m=\u001b[32m'2014'\u001b[0m,\n",
       "                \u001b[33mcommon_usage\u001b[0m=\u001b[32m'image generation, data augmentation, and anomaly detection'\u001b[0m,\n",
       "                \u001b[33mpros\u001b[0m=\u001b[32m'capable of generating high-quality and realistic samples, and can learn complex data \u001b[0m\n",
       "\u001b[32mdistributions'\u001b[0m,\n",
       "                \u001b[33mcons\u001b[0m=\u001b[32m'training instability, mode collapse, and difficulty in evaluating the quality of generated \u001b[0m\n",
       "\u001b[32msamples'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NeuralNetworkModel(BaseModel):\n",
    "    name: str = Field(description=\"Name\")\n",
    "    year: str = Field(description=\"The year of creation\")\n",
    "    common_usage: str = Field(description=\"Fields where commonly applicable\")\n",
    "    pros: str = Field(description=\"Pros of the architecture\")\n",
    "    cons: str = Field(description=\"Cons of the architecture\")\n",
    "\n",
    "class ResponseSchema(BaseModel):\n",
    "    neural_networks: List[NeuralNetworkModel]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Provide concise information for: {input}\")\n",
    "llm_structured = llm.with_structured_output(ResponseSchema)\n",
    "\n",
    "chain = prompt_template | llm_structured \n",
    "\n",
    "prompt_values = [\n",
    "    {\"input\": \"Feedforward Neural Networks\"},\n",
    "    {\"input\": \"Convolutional Neural Networks\"},\n",
    "    {\"input\": \"Recurrent Neural Networks\"},\n",
    "    {\"input\": \"Generative Adversarial Networks\"}\n",
    "]\n",
    "\n",
    "result = chain.batch(prompt_values)\n",
    "\n",
    "# we will get a list with the two plain text outputs\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
