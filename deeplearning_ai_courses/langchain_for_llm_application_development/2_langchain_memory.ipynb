{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142a6967",
   "metadata": {},
   "source": [
    "# Course info\n",
    "\n",
    "DeepLearning.ai course: [LangChain for LLM Application Development](https://learn.deeplearning.ai/courses/langchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c4f21",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "- ConversationBufferMemory\n",
    "  - This memory allows for storing of messages and then extracts the messages in a variable.\n",
    "- ConversationBufferWindowMemory\n",
    "  - This memory keeps a list of the interactions of the conversation over time. It only uses the last K interactions.\n",
    "- ConversationTokenBufferMemory\n",
    "  - This memory keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions.\n",
    "- ConversationSummaryMemory\n",
    "  - This memory creates a summary of the conversation over time.\n",
    "\n",
    "## Additional Memory Types (not covered in this Notebook)\n",
    "- Vector data memory\n",
    "  - Stores text (from conversation or elsewhere) in a vector database and retrieves the most relevant\n",
    "blocks of text.\n",
    "- Entity memories\n",
    "  - Using an LLM, it remembers details about specific entities.\n",
    "\n",
    "You can also use multiple memories at one time.\n",
    "E.g., Conversation memory + Entity memory to recall individuals.\n",
    "\n",
    "You can also store the conversation in a conventional database (such as key-value store or SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bfc48a",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4d94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_chat_model\n",
    "\n",
    "llm = get_chat_model(temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badfec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5356b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/vd99d1jj46l4pg5l2_852z280000gn/T/ipykernel_11955/2129424381.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/var/folders/l4/vd99d1jj46l4pg5l2_852z280000gn/T/ipykernel_11955/2129424381.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164f268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi Andrew! It's nice to meet you. My name is, well, I don't really *have* a name in the traditional sense. You can call me AI, or if you prefer, you can think of me as a large language model. I'm trained by Google, and I'm designed to be helpful and informative. I'm glad to be chatting with you today! What can I do for you?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34ae819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hi Andrew! It's nice to meet you. My name is, well, I don't really *have* a name in the traditional sense. You can call me AI, or if you prefer, you can think of me as a large language model. I'm trained by Google, and I'm designed to be helpful and informative. I'm glad to be chatting with you today! What can I do for you?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ah, a classic! 1 + 1 equals 2. It's one of the fundamental building blocks of arithmetic. Is there anything else I can calculate for you? I can handle much more complex equations if you'd like to test me! I can even do things like calculate the square root of a number, or solve for variables in an algebraic equation. Just let me know!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd35562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hi Andrew! It's nice to meet you. My name is, well, I don't really *have* a name in the traditional sense. You can call me AI, or if you prefer, you can think of me as a large language model. I'm trained by Google, and I'm designed to be helpful and informative. I'm glad to be chatting with you today! What can I do for you?\n",
      "Human: What is 1+1?\n",
      "AI: Ah, a classic! 1 + 1 equals 2. It's one of the fundamental building blocks of arithmetic. Is there anything else I can calculate for you? I can handle much more complex equations if you'd like to test me! I can even do things like calculate the square root of a number, or solve for variables in an algebraic equation. Just let me know!\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You told me your name is Andrew! So, your name is Andrew. Is that correct? I want to make sure I'm remembering things properly.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bd1448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hi Andrew! It's nice to meet you. My name is, well, I don't really *have* a name in the traditional sense. You can call me AI, or if you prefer, you can think of me as a large language model. I'm trained by Google, and I'm designed to be helpful and informative. I'm glad to be chatting with you today! What can I do for you?\n",
      "Human: What is 1+1?\n",
      "AI: Ah, a classic! 1 + 1 equals 2. It's one of the fundamental building blocks of arithmetic. Is there anything else I can calculate for you? I can handle much more complex equations if you'd like to test me! I can even do things like calculate the square root of a number, or solve for variables in an algebraic equation. Just let me know!\n",
      "Human: What is my name?\n",
      "AI: You told me your name is Andrew! So, your name is Andrew. Is that correct? I want to make sure I'm remembering things properly.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cfc5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Andrew\\nAI: Hi Andrew! It's nice to meet you. My name is, well, I don't really *have* a name in the traditional sense. You can call me AI, or if you prefer, you can think of me as a large language model. I'm trained by Google, and I'm designed to be helpful and informative. I'm glad to be chatting with you today! What can I do for you?\\nHuman: What is 1+1?\\nAI: Ah, a classic! 1 + 1 equals 2. It's one of the fundamental building blocks of arithmetic. Is there anything else I can calculate for you? I can handle much more complex equations if you'd like to test me! I can even do things like calculate the square root of a number, or solve for variables in an algebraic equation. Just let me know!\\nHuman: What is my name?\\nAI: You told me your name is Andrew! So, your name is Andrew. Is that correct? I want to make sure I'm remembering things properly.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e215f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2929703",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2cec211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b5fab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc5ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dddc938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29129172",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a05c324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/vd99d1jj46l4pg5l2_852z280000gn/T/ipykernel_11955/198677075.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5c832a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb9d92c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeebf57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d35b4aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi Andrew! It's nice to meet you. My name is, well, I don't really *have* a name in the traditional sense. You can call me AI, or if you prefer, you can think of me as a large language model. I'm trained by Google, and I'm designed to be helpful and informative. I'm glad to be chatting with you today! What can I do for you?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17198931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hi Andrew! It's nice to meet you. My name is, well, I don't really *have* a name in the traditional sense. You can call me AI, or if you prefer, you can think of me as a large language model. I'm trained by Google, and I'm designed to be helpful and informative. I'm glad to be chatting with you today! What can I do for you?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's a classic! 1 + 1 equals 2. It's one of the first things many people learn in arithmetic. Is there anything else I can calculate for you? I can handle much more complex equations than that, including things like calculus, statistics, and even some basic symbolic algebra. Just let me know!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41f22404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: That's a classic! 1 + 1 equals 2. It's one of the first things many people learn in arithmetic. Is there anything else I can calculate for you? I can handle much more complex equations than that, including things like calculus, statistics, and even some basic symbolic algebra. Just let me know!\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I do not have access to personal information, so I don\\'t know your name. I\\'m designed to be helpful and informative, but I can\\'t access data that hasn\\'t been explicitly shared with me. If you\\'d like me to know your name, you could tell me! Otherwise, I\\'ll just keep referring to you as \"Human\" for now. ðŸ˜Š'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36699fcc",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5292d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19342405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=20)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d4dc20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03882db1",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bd4f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea19d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/vd99d1jj46l4pg5l2_852z280000gn/T/ipykernel_11955/1387621936.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n"
     ]
    }
   ],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26ab2c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI, asks how it is doing, states they are just hanging out, and then asks what is on the schedule for the day.\\nAI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f3af796",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7691b3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI, asks how it is doing, states they are just hanging out, and then asks what is on the schedule for the day.\n",
      "AI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, since you\\'re meeting with a customer who\\'s driving a long way to see the latest in AI, you\\'ll want a demo that\\'s both impressive and relevant to their potential needs. Here are a few ideas, keeping in mind I don\\'t know their specific industry or interests:\\n\\n**Option 1: Personalized Content Generation with a Few-Shot Prompt**\\n\\n*   **Concept:** Showcase the ability of an LLM to generate highly personalized content based on a small amount of input data.\\n*   **Demo:**\\n    1.  **Start with a brief explanation:** \"We can use LLMs to create tailored content for various purposes. Let me show you how we can generate a personalized marketing email, blog post, or even a product description based on just a few examples.\"\\n    2.  **Gather a few \"seed\" examples:** Ask the customer for 2-3 examples of their existing marketing materials, product descriptions, or customer communications. The more specific and representative these examples are, the better.\\n    3.  **Use a few-shot prompt:** Craft a prompt that instructs the LLM to generate a new piece of content that is similar in style, tone, and content to the examples provided. For example: \"Generate a marketing email for [product/service] that is similar in style and tone to the following examples: [example 1], [example 2], [example 3].\"\\n    4.  **Run the demo and highlight the results:** Show the generated content and emphasize how it captures the essence of their brand and messaging. Point out any specific keywords or phrases that were successfully incorporated.\\n    5.  **Discuss customization options:** Explain how the prompt can be further refined to control the length, tone, and focus of the generated content.\\n\\n**Why this is good:** It\\'s highly customizable, shows immediate value, and demonstrates the power of few-shot learning.\\n\\n**Option 2: Question Answering over a Knowledge Base**\\n\\n*   **Concept:** Demonstrate the ability of an LLM to answer questions based on a specific set of documents or data.\\n*   **Demo:**\\n    1.  **Prepare a knowledge base:** Before the meeting, gather a collection of documents that are relevant to the customer\\'s industry or business. This could include their website content, product manuals, industry reports, or internal documentation.\\n    2.  **Use Langchain to create a vector store:** Use Langchain to ingest the documents and create a vector store. This will allow the LLM to quickly retrieve relevant information based on the user\\'s questions.\\n    3.  **Ask questions:** Ask the LLM questions about the knowledge base and show how it can provide accurate and informative answers. For example, \"What are the key benefits of [product/service]?\" or \"What are the latest trends in [industry]?\"\\n    4.  **Highlight the benefits:** Emphasize how this technology can be used to improve customer service, streamline internal knowledge sharing, and automate research tasks.\\n\\n**Why this is good:** It showcases the ability of LLMs to process and understand large amounts of information, and it has practical applications for many businesses.\\n\\n**Option 3: Code Generation**\\n\\n*   **Concept:** Demonstrate the ability of an LLM to generate code based on natural language instructions.\\n*   **Demo:**\\n    1.  **Start with a simple example:** Ask the LLM to generate a simple function in a language the customer is likely familiar with (e.g., Python, JavaScript). For example: \"Write a Python function that calculates the factorial of a number.\"\\n    2.  **Gradually increase the complexity:** As the demo progresses, ask the LLM to generate more complex code snippets, such as a function that performs a specific data analysis task or a simple web application.\\n    3.  **Highlight the benefits:** Emphasize how this technology can be used to accelerate software development, automate repetitive coding tasks, and empower non-programmers to create simple applications.\\n\\n**Why this is good:** It\\'s visually impressive and demonstrates the potential of LLMs to revolutionize the software development process.\\n\\n**Important Considerations for ALL Demos:**\\n\\n*   **Keep it concise:** Aim for a demo that lasts no more than 10-15 minutes.\\n*   **Focus on relevance:** Tailor the demo to the customer\\'s specific needs and interests.\\n*   **Explain the technology:** Clearly explain the underlying technology and how it works.\\n*   **Highlight the benefits:** Emphasize the potential benefits of the technology for the customer\\'s business.\\n*   **Be prepared to answer questions:** Anticipate potential questions and have answers ready.\\n*   **Have a backup plan:** Always have a backup demo in case the primary demo fails.\\n*   **Practice, practice, practice!** Rehearse the demo beforehand to ensure a smooth and professional presentation.\\n\\nBefore you decide, consider:\\n\\n*   **What is the customer\\'s industry?**\\n*   **What are their biggest pain points?**\\n*   **What are their current technology investments?**\\n\\nKnowing the answers to these questions will help you choose the most impactful demo. Good luck!'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbfa1ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI, asks how it is doing, states they are just hanging out, and then asks what is on the schedule for the day. The AI responds with the schedule: an 8am meeting with the product team, time to work on the LangChain project from 9am-12pm, and lunch at noon with a customer to demo the latest in AI. The human asks what would be a good demo to show. The AI suggests three options: personalized content generation with a few-shot prompt, question answering over a knowledge base using Langchain, and code generation, providing details and considerations for each.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
